[[Docker_Swarm]]
## Deploy Application on Docker Swarm Cluster

Docker Swarm is native clustering for Docker. It allows you create and access to a pool of Docker hosts using the full suite of Docker tools. Because Docker Swarm serves the standard Docker API, any tool that already communicates with a Docker daemon can use Swarm to transparently scale to multiple hosts

### Key Components of Docker Swarm

.Key Components of Docker Swarm
image::images/docker-swarm-components.png[]

*Swarm Manager*: Docker Swarm has a Manager, that is a pre-defined Docker Host, and is a single point for all administration. The swarm manager orchestrates and schedules containers on the entire cluster. Currently only a single instance of manager is allowed in the cluster. This is a SPOF for high availability architectures and additional managers will be allowed in a future version of Swarm with https://github.com/docker/swarm/issues/598[#598].

*Swarm Nodes*: The containers are deployed on Nodes that are additional Docker Hosts. Each Swarm Node must be accessible by the manager, each node must listen to the same network interface (TCP port). Each node runs a Docker Swarm agent that registers the referenced Docker daemon, monitors it, and updates the discovery backend with the node’s status. The containers run on a node.

*Scheduler Strategy*: Different scheduler strategies ("`binpack`", "`spread`" (default), and "`random`") can be applied to pick the best node to run your container. The default strategy optimizes the node for least number of running containers. There are multiple kinds of filters, such as constraints and affinity.  This should allow for a decent scheduling algorithm.

*Node Discovery Service*: By default, Swarm uses hosted discovery service, based on Docker Hub, using tokens to discover nodes that are part of a cluster. However etcd, consul, and ZooKeeper can be also be used for service discovery as well. This is particularly useful if there is no access to Internet, or you are running the setup in a closed network. A new discovery backend can be created as explained here. It would be useful to have the hosted Discovery Service inside the firewall and https://github.com/docker/swarm/issues/660[#660] will discuss this.

**Standard Docker API:** Docker Swarm serves the standard Docker API and thus any tool that talks to a single Docker host will seamlessly scale to multiple hosts now. That means that if you were using shell scripts using Docker CLI to configure multiple Docker hosts, the same CLI would can now talk to Swarm cluster and Docker Swarm will then act as proxy and run it on the cluster.

There are lots of other concepts but these are the main ones.

#### Set up a key-value store

. An overlay network requires a key-value store. The key-value store holds information about the network state which includes discovery, networks, endpoints, IP addresses, and more. Docker supports Consul, Etcd, and ZooKeeper key-value stores. This example uses Consul.

  #From Internet
  docker-machine create -d virtualbox  --engine-insecure-registry=classroom.example.com:5000 mh-keystore
  
  #From Instructor
  docker-machine create -d virtualbox --engine-insecure-registry=classroom.example.com:5000 --virtualbox-boot2docker-url=http://classroom.example.com:8082/downloads/boot2docker.iso mh-keystore
  
. Start consul

  #From Internet
  docker $(docker-machine config mh-keystore) run -d -p "8500:8500"  -h "consul" progrium/consul -server -bootstrap

  #From Instructor
  docker $(docker-machine config mh-keystore) run -d -p "8500:8500"  -h "consul" classroom.example.com:5000/consul -server -bootstrap

### Create a Docker Swarm Cluster

. Swarm is fully integrated with Docker Machine, and so is the easiest way to get started. Let's create a Swarm Master next:


  #From Internet
  docker-machine create -d virtualbox  --engine-insecure-registry=classroom.example.com:5000 --swarm --swarm-master   --swarm-discovery="consul://$(docker-machine ip mh-keystore):8500"   --engine-opt="cluster-store=consul://$(docker-machine ip mh-keystore):8500"   --engine-opt="cluster-advertise=eth1:2376" swarm-master
  
  #From Instructor
  docker-machine create -d virtualbox --engine-insecure-registry=classroom.example.com:5000 --virtualbox-boot2docker-url=http://classroom.example.com:8082/downloads/boot2docker.iso --swarm --swarm-master   --swarm-discovery="consul://$(docker-machine ip mh-keystore):8500"   --engine-opt="cluster-store=consul://$(docker-machine ip mh-keystore):8500"   --engine-opt="cluster-advertise=eth1:2376" swarm-master

. Create a Swarm node

  #From Internet
  docker-machine create -d virtualbox --engine-insecure-registry=classroom.example.com:5000 --swarm --swarm-discovery="consul://$(docker-machine ip mh-keystore):8500"   --engine-opt="cluster-store=consul://$(docker-machine ip mh-keystore):8500" --engine-opt="cluster-advertise=eth1:2376" swarm-node-01

  #From Instructor
  docker-machine create -d virtualbox --engine-insecure-registry=classroom.example.com:5000 --virtualbox-boot2docker-url=http://classroom.example.com:8082/downloads/boot2docker.iso --swarm --swarm-discovery="consul://$(docker-machine ip mh-keystore):8500"   --engine-opt="cluster-store=consul://$(docker-machine ip mh-keystore):8500" --engine-opt="cluster-advertise=eth1:2376" swarm-node-01

. To make it a real cluster, let's create a second node:

  #From Internet
  docker-machine create -d virtualbox --engine-insecure-registry=classroom.example.com:5000 --swarm --swarm-discovery="consul://$(docker-machine ip mh-keystore):8500"   --engine-opt="cluster-store=consul://$(docker-machine ip mh-keystore):8500" --engine-opt="cluster-advertise=eth1:2376" swarm-node-02

  #From Instructor
  docker-machine create -d virtualbox --engine-insecure-registry=classroom.example.com:5000 --virtualbox-boot2docker-url=http://classroom.example.com:8082/downloads/boot2docker.iso --swarm --swarm-discovery="consul://$(docker-machine ip mh-keystore):8500"   --engine-opt="cluster-store=consul://$(docker-machine ip mh-keystore):8500" --engine-opt="cluster-advertise=eth1:2376" swarm-node-02

. List all the nodes created so far:

  docker-machine ls

This shows the output similar to the one below:

[source, text]
----
docker-machine ls
NAME            ACTIVE   DRIVER       STATE     URL                         SWARM
lab                      virtualbox   Running   tcp://192.168.99.101:2376   
swarm-master    *        virtualbox   Running   tcp://192.168.99.102:2376   swarm-master (master)
swarm-node-01            virtualbox   Running   tcp://192.168.99.103:2376   swarm-master
swarm-node-02            virtualbox   Running   tcp://192.168.99.104:2376   swarm-master
----

The machines that are part of the cluster have the cluster’s name in the SWARM column, blank otherwise. For example, "`lab`" is the standalone machine where as all other machines are part of the "`swarm-master`" cluster. The Swarm master is also identified by (master) in the SWARM column.

. Connect to the Swarm cluster and find some information about it:

  eval "$(docker-machine env --swarm swarm-master)"
  docker info

This shows the output as:

[source, text]
----
> docker info
Containers: 4
Images: 3
Role: primary
Strategy: spread
Filters: health, port, dependency, affinity, constraint
Nodes: 3
 swarm-master: 192.168.99.107:2376
  └ Status: Healthy
  └ Containers: 2
  └ Reserved CPUs: 0 / 1
  └ Reserved Memory: 0 B / 1.021 GiB
  └ Labels: executiondriver=native-0.2, kernelversion=4.1.13-boot2docker, operatingsystem=Boot2Docker 1.9.1 (TCL 6.4.1); master : cef800b - Fri Nov 20 19:33:59 UTC 2015, provider=virtualbox, storagedriver=aufs
 swarm-node-01: 192.168.99.108:2376
  └ Status: Healthy
  └ Containers: 1
  └ Reserved CPUs: 0 / 1
  └ Reserved Memory: 0 B / 1.021 GiB
  └ Labels: executiondriver=native-0.2, kernelversion=4.1.13-boot2docker, operatingsystem=Boot2Docker 1.9.1 (TCL 6.4.1); master : cef800b - Fri Nov 20 19:33:59 UTC 2015, provider=virtualbox, storagedriver=aufs
 swarm-node-02: 192.168.99.109:2376
  └ Status: Healthy
  └ Containers: 1
  └ Reserved CPUs: 0 / 1
  └ Reserved Memory: 0 B / 1.021 GiB
  └ Labels: executiondriver=native-0.2, kernelversion=4.1.13-boot2docker, operatingsystem=Boot2Docker 1.9.1 (TCL 6.4.1); master : cef800b - Fri Nov 20 19:33:59 UTC 2015, provider=virtualbox, storagedriver=aufs
CPUs: 3
Total Memory: 3.064 GiB
Name: swarm-master
----

There are 3 nodes – one Swarm master and 2 Swarm nodes. There is a total of 4 containers running in this cluster – one Swarm agent on master and each node, and there is an additional swarm-agent-master running on the master. This can be verified by connecting to the master and listing all the containers.


### Deploy Java EE Application to Docker Swarm Cluster

The complete cluster is in place now, and we need to deploy the Java EE application to it.

Swarm takes care for the distribution of deployments across the nodes. The only thing, we need to do is to deploy the application as already explained in <<JavaEE_Docker_Network>>.

. Create a docker network as:

[source, text]
----
docker network create mynet
----

. Start PostgreSQL server as:

[source, text]
----
#From Internet
docker run --name db -d -p 5432:5432 --net mynet -e POSTGRES_USER=ticketmonster -e POSTGRES_PASSWORD=ticketmonster-docker postgres

#From Instructor
docker run --name db -d -p 5432:5432 --net mynet -e POSTGRES_USER=ticketmonster -e POSTGRES_PASSWORD=ticketmonster-docker classroom.example.com:5000/postgres
----

`-e` define environment variables that are read by the database at startup and allow us to access the database with this user and password.

. Start WildFly and deploy Java EE 7 application as:

[source, text]
----
#From Internet
docker run -d --name widlfy-ticketmonster --net mynet -p 9990:9990 -p 8080:8080 rafabene/wildfly-ticketmonster /opt/jboss/wildfly/bin/standalone.sh -b 0.0.0.0

#From Instructor
docker run -d --name widlfy-ticketmonster --net mynet -p 8080:8080 classroom.example.com:5000/wildfly-ticketmonster /opt/jboss/wildfly/bin/standalone.sh -b 0.0.0.0
----

This is using the https://docs.docker.com/engine/userguide/networking/dockernetworks/[Docker Network] explained earlier.

. Check state of the cluster as:

[source, text]
----
> docker info
Containers: 6
Images: 6
Role: primary
Strategy: spread
Filters: health, port, dependency, affinity, constraint
Nodes: 3
 swarm-master: 192.168.99.107:2376
  └ Status: Healthy
  └ Containers: 2
  └ Reserved CPUs: 0 / 1
  └ Reserved Memory: 0 B / 1.021 GiB
  └ Labels: executiondriver=native-0.2, kernelversion=4.1.13-boot2docker, operatingsystem=Boot2Docker 1.9.1 (TCL 6.4.1); master : cef800b - Fri Nov 20 19:33:59 UTC 2015, provider=virtualbox, storagedriver=aufs
 swarm-node-01: 192.168.99.108:2376
  └ Status: Healthy
  └ Containers: 2
  └ Reserved CPUs: 0 / 1
  └ Reserved Memory: 0 B / 1.021 GiB
  └ Labels: executiondriver=native-0.2, kernelversion=4.1.13-boot2docker, operatingsystem=Boot2Docker 1.9.1 (TCL 6.4.1); master : cef800b - Fri Nov 20 19:33:59 UTC 2015, provider=virtualbox, storagedriver=aufs
 swarm-node-02: 192.168.99.109:2376
  └ Status: Healthy
  └ Containers: 2
  └ Reserved CPUs: 0 / 1
  └ Reserved Memory: 0 B / 1.021 GiB
  └ Labels: executiondriver=native-0.2, kernelversion=4.1.13-boot2docker, operatingsystem=Boot2Docker 1.9.1 (TCL 6.4.1); master : cef800b - Fri Nov 20 19:33:59 UTC 2015, provider=virtualbox, storagedriver=aufs
CPUs: 3
Total Memory: 3.064 GiB
Name: swarm-master
----

Run a docker ps so you can verify that each container is running on a different node:

[source, text]
----
> docker ps 
CONTAINER ID        IMAGE                                 COMMAND                  CREATED             STATUS              PORTS                                               NAMES
5ae7b0b910c8        rafabene/wildfly-ticketmonster        "/bin/sh -c '/opt/jbo"   16 seconds ago      Up 15 seconds       8009/tcp, 9990/tcp, 192.168.99.109:8080->8080/tcp   swarm-node-02/wildfly-ticketmonster
9d086c032357        classroom.example.com:5000/postgres   "/docker-entrypoint.s"   45 minutes ago      Up 45 minutes       192.168.99.108:5432->5432/tcp                       swarm-node-01/db
----

. Access the application as:

[source, text]
----
open http://192.168.99.109:8080/ticket-monster
----

NOTE: It might take a while for the container to come up. Wait for the server to complete the startup.

.Java EE Application Output
image::images/javaee-ticketmonster.png[]


NOTE: If you get a 404 or any other error, wait for a little longer until the containers are started up.

### Deploy Java EE Application to Docker Swarm Cluster using Docker Compose

<<Docker_Compose>> explains how multi container applications can be easily started using Docker Compose.

. Stop the PostgreSQL and WildFly containers:

  docker ps -a | grep wildfly | awk '{print $1}' | xargs docker rm -f
  docker ps -a | grep db | awk '{print $1}' | xargs docker rm -f
    
. Use the `docker-compose.yml` file explained in <<Docker_Compose>> to start the containers as:

  docker-compose pull
  docker-compose up -d
  Creating attendees_db_1...
  Creating attendees_mywildfly_1...


. Run a docker ps so you can verify that each container is running on a different node:

[source, text]
----
> docker ps 
CONTAINER ID        IMAGE                                 COMMAND                  CREATED             STATUS              PORTS                                               NAMES
5ae7b0b910c8        rafabene/wildfly-ticketmonster        "/bin/sh -c '/opt/jbo"   16 seconds ago      Up 15 seconds       8009/tcp, 9990/tcp, 192.168.99.109:8080->8080/tcp   swarm-node-02/wildfly-ticketmonster
9d086c032357        classroom.example.com:5000/postgres   "/docker-entrypoint.s"   45 minutes ago      Up 45 minutes       192.168.99.108:5432->5432/tcp                       swarm-node-01/db
----

. Check the logs

  docker-compose logs
  

////
TODO Add container visualiation using https://github.com/javaee-samples/docker-java/issues/55.
////